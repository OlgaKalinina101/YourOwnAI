# YourOwnAI ğŸ¤–

![Android](https://img.shields.io/badge/Android-26%2B-green.svg)
![Kotlin](https://img.shields.io/badge/Kotlin-100%25-purple.svg)
![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)
![Status](https://img.shields.io/badge/Status-Beta-orange.svg)

**Your AI, Your Rules. No Corporations, No Censorship, No Limits.**

YourOwnAI is a privacy-first Android application that gives you complete control over your AI assistant. Use your own API keys, store everything locally, and define your AI's personality exactly how you want it.

**Latest:** ğŸ‰ **Multimodal support** - attach images and documents to 26 different models! Plus speech-to-text, pinned favorites, and smart chat sorting. ğŸ¹ **NEW: Keyboard sound & vibration** - immersive typing effects when AI responds!

**Current Status:** ğŸš€ Beta - Feature-complete, actively polished

---

## ğŸ“¸ Screenshots

<div align="center">

### ğŸ’¬ Chat Interface
<table>
  <tr>
    <td><img src="examples/chat1.jpg" width="200"/></td>
    <td><img src="examples/chat2.jpg" width="200"/></td>
    <td><img src="examples/chat3.jpg" width="200"/></td>
    <td><img src="examples/chat4.jpg" width="200"/></td>
  </tr>
</table>

### ğŸ¤– AI Models & Settings
<table>
  <tr>
    <td><img src="examples/models1.jpg" width="200"/></td>
    <td><img src="examples/models2.jpg" width="200"/></td>
    <td><img src="examples/local_models.jpg" width="200"/></td>
  </tr>
</table>

### âœ¨ Onboarding & Customization
<table>
  <tr>
    <td><img src="examples/onboarding.gif" width="300" style="max-width: 100%; height: auto;"/></td>
    <td><img src="examples/settings.gif" width="300" style="max-width: 100%; height: auto;"/></td>
    <td><img src="examples/chat.gif" width="300" style="max-width: 100%; height: auto;"/></td>  
  </tr>
</table>

</div>

---

## ğŸ¯ Why YourOwnAI?

Fed up with:
- ğŸ’¸ **Subscription fees** that profile and monetize your conversations?
- ğŸ•µï¸ **Corporate oversight** deciding what's "appropriate" to discuss?
- ğŸ”’ **Vendor lock-in** limiting your AI provider choices?
- â˜ï¸ **Cloud dependency** where your data lives on someone else's servers?

**YourOwnAI gives you back control:**
- âœ… Use **any AI provider** with your API keys - no middleman
- âœ… **100% local storage** - conversations never leave your device
- âœ… **Switch providers** freely - Deepseek, OpenAI, x.ai, or local models
- âœ… **Offline capable** - download models and chat without internet
- âœ… **Open source** - audit the code, contribute, or fork it

## ğŸ¯ Core Philosophy

Every person has the right to interact with AI on their own terms - not what corporations deem "acceptable," "appropriate," or "safe." Whether it's a digital companion, a work assistant, a creative partner, or anything else - **you decide**.

### Key Principles

**Privacy**
- ğŸ” All conversations encrypted and stored locally
- ğŸ”‘ API keys secured with Android Keystore System
- ğŸš« Zero telemetry - no analytics, tracking, or profiling
- ğŸ“± Data never leaves your device (unless you use cloud API)

**Control**
- âš™ï¸ Full customization of AI behavior via system prompts
- ğŸ›ï¸ Adjust temperature, top-p, max tokens, context length
- ğŸ§  Optional "Deep Empathy" mode for emotional intelligence
- ğŸ”„ Switch between providers and models freely

**Freedom**
- ğŸŒ Direct API access - no corporate intermediaries
- ğŸ’° No subscriptions - pay only for your API usage
- ğŸ  Offline mode with local models (Qwen 2.5, Llama 3.2)
- ğŸ“– Open source - inspect, modify, or fork the code

## ğŸ¨ Design Philosophy

> **"The app is a canvas. You and your AI create the masterpiece."**

YourOwnAI follows a **maximally neutral design approach**. The interface doesn't impose mood, personality, or emotional tone - that comes from your customization and your AI's character.

### Visual Design Principles

**Neutrality First**
- No "cute" or "playful" design elements
- No corporate color schemes that suggest trust/innovation/friendliness
- No fonts with built-in personality
- Clean, functional, minimalist interface
- Content is king, UI is invisible

**Material 3 Dynamic Color (Android 12+)**
- Colors adapt from your device wallpaper
- Familiar, personalized, yet neutral
- Respects system dark/light theme
- Falls back to grayscale on older devices

**Typography**
- **Roboto** (Android default) - maximally neutral, universally familiar
- Option to use system font (respects user's device settings)
- Adjustable text size for accessibility
- No decorative or "emotional" typefaces

**User Customization Options**
- System colors (Dynamic Color) or neutral grayscale
- Light/dark/system theme
- Custom accent color (optional, for those who want it)
- Font size adjustments
- UI density options

**The Philosophy:**
The app should feel like a **tool**, not a product with personality. It's your space to build whatever relationship with AI you choose - companion, assistant, note-taker, or anything else. The design stays out of the way.

## âœ¨ Features

### âœ… Implemented & Working

#### ğŸ” Privacy & Control
- **Local-first architecture** - all data stored on device with Room Database
- **Encrypted API keys** - secured with Android Keystore System
- **Android Auto Backup** - automatic backup of chats and settings (API keys excluded)
- **No backend** - direct communication with AI providers
- **No tracking** - zero analytics, telemetry, or user profiling
- **Onboarding customization** - theme, colors, fonts, text size
- **Dynamic theming** - Material 3 Dynamic Color from your wallpaper
- **Settings persistence** - all preferences saved locally

#### ğŸ’¬ Chat Experience
- **Streaming responses** - real-time AI generation with smooth animations
- **Multiple conversations** - organize chats by topic with smart sorting (newest first)
- **Model switching** - change AI provider/model per conversation
- **Pin favorite models** - star icon to pin frequently used models to top of list
- **Multimodal support (NEW!)** - attach images and documents to your messages:
  - **Images** - JPEG, PNG, GIF, WebP support
  - **Documents** - PDF, TXT, DOC, DOCX support (model-dependent)
  - **26 models** with vision/document capabilities
  - Automatic compression and encoding
  - In-chat preview of attachments
  - Model-specific limits displayed (e.g., "Up to 100 images")
- **Speech-to-text input** - dictate messages using Android STT
  - Microphone button dynamically appears when input is empty
  - Real-time transcription with visual feedback
  - Pulsating animation during listening
- **Keyboard sound & vibration (NEW!)** - immersive typing effects:
  - Realistic typing sounds when AI responds
  - Haptic feedback (vibration) synchronized with typing
  - Customizable: enable/disable sound and vibration separately
  - Smart detection of sentence endings for send sound
  - Configurable in Settings > Sound & Haptics
- **Grok-style message input** - minimalist design with smart controls:
  - Send button transforms into microphone when empty
  - Attachment menu inside input field (left side)
  - Dropdown for Image vs Document selection
  - Clean, unobtrusive UI
- **Rich markdown rendering**:
  - **bold**, *italic*, [clickable links](url)
  - > blockquotes for emphasis
  - # Headings (H1, H2, H3)
  - Horizontal rules (---, ***, ___)
- **Message reply (swipe)** - Telegram-style message replies
  - Reply to any message with visual preview
  - Replied message shown in context above input
  - Click preview to scroll to original message
  - Visual indicator in message bubbles ("Replied to:")
  - Swipe context sent to AI with configurable prompt
- **Request logs** - inspect full API requests (JSON) for debugging
  - View system prompt, messages, context (Memory, RAG, Deep Empathy, Swipe)
  - Copy logs for troubleshooting
- **Message history** - configurable context length (1-25 messages)
- **Context Inheritance (NEW!)** - fork conversations with inherited message history
  - Select source chat when creating new conversation
  - Last N message pairs automatically loaded into context
  - Inherited messages gradually replaced as new conversation grows
- **Conversation titles** - auto-generated or manual edit
- **Context-aware responses** - AI uses Memory, RAG, Deep Empathy, and Swipe context (API models only)
- **Import/Export chats** - export to text format, import from txt files or clipboard

#### ğŸ™ï¸ Voice Chat (NEW!)
- **Real-time voice conversation** - talk naturally with Grok AI
- **5 voice options** - Ara (female, warm), Rex (male, confident), Sal (neutral, smooth), Eve (female, energetic), Leo (male, authoritative)
- **System prompt selection** - choose personality from your saved prompts
- **User context support** - voice chat uses your Context from Settings
- **Audio visualization** - real-time waveform when speaking/listening
- **Tap-to-talk** - simple microphone button (tap to start, tap to stop)
- **Persistent history** - previous conversations saved locally (last 100 messages)
- **Clear history** - delete button to start fresh
- **Request logs** - view full voice session details (prompt, voice, context)
- **xAI Grok Voice Agent API** - powered by grok-beta with 24kHz PCM16 audio

#### ğŸ¤– AI Providers & Models
- **Deepseek** - deepseek-chat, deepseek-reasoner (text only)
- **OpenAI** - GPT-5.2, GPT-5.1, GPT-4o (multimodal: images + PDFs)
    - **GPT-4.1 Series** (NEW!) - GPT-4.1 (gpt-4.1 or gpt-4.1-2025-04-14 snapshot)
        - Strongest non-reasoning model with 1M token context, excels at instruction following, coding, long docs/codebases
        - Multimodal: text + images (same as GPT-4o)
        - Smart parameter detection (max_completion_tokens, conditional temperature)
        - Up to 500 images or 50 documents per request
- **x.ai (Grok)** - Grok 4.1, Grok 4, Grok 3, Grok Code (multimodal: images + files)
    - Unlimited images (20MB each)
    - 50 documents (PDF, TXT, MD, CSV, JSON, code files)
    - 48MB per file limit
- **OpenRouter (NEW!)** - Access 200+ models with one API key:
    - **Claude** (6 models) - Sonnet 4.5/4/3.7, Opus 4.5, Haiku 4.5/3.5
        - 100 images + native PDF support (up to 100 pages)
        - 32MB total request size
    - **Llama 4** (2 models) - Maverick, Scout
        - 10 images, native multimodal with early fusion
        - 10M token context (Scout)
    - **Llama 3.1 Series** (NEW!)
        - Llama 3.1-euryale (sao10k/l3.1-euryale-70b) â€” Focused on creative roleplay, immersive storytelling, emotional depth
        - Nous: Hermes 3 70B (nousresearch/hermes-3-llama-3.1-70b) â€” Powerful alignment to user, excellent steering/control, agentic + roleplay capabilities
    - **Gemini** (4 models) - 3 Pro/Flash, 2.5 Pro/Flash
        - 10 files per prompt, up to 100MB each
        - PDF support (30MB/2000 pages)
        - Text, images, audio, video support
    - **GPT-4o** - Same capabilities as OpenAI direct
- **Local inference** - Qwen 2.5 1.7B (950MB), Llama 3.2 3B (1.9GB)
    - Download queue system (one at a time)
    - Progress tracking with UI updates
    - Automatic corruption detection (GGUF validation)
    - Thread-safe loading and generation (Mutex)

**Total: 26 models with multimodal support (images/documents)!**

#### âš™ï¸ AI Configuration
- **System prompt editor** - customize AI personality
- **Local system prompt** - separate prompt for offline models
- **User context** - persistent facts about you
- **Temperature** (0.0-2.0) - control creativity vs consistency
- **Top-P** (0.0-1.0) - nucleus sampling for diversity
- **Max tokens** - response length limit (256-8192)
- **Message history limit** - context window size (1-25 messages)
- **Advanced settings** - collapsible sections for each AI feature

#### ğŸ§  Advanced AI Features (API Models Only)
- **Deep Empathy mode** - emotional intelligence with dialogue focus detection
  - Automatic analysis of strong emotional moments
  - Configurable focus prompt ("Ğ£Ğ´ĞµÑ€Ğ¶Ğ¸ ÑÑ‚Ğ¾ Ñ€ÑĞ´Ğ¾Ğ¼: {dialogue_focus}")
  - Custom analysis prompt with locked JSON format
  - Real-time context injection for empathetic responses
- **Long-term Memory** - persistent memory across conversations
  - Automatic extraction from user messages
  - Smart filtering - excludes non-meaningful responses ("ĞĞµÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸", etc.)
  - Semantic search with embeddings (cosine similarity)
  - Configurable extraction prompt with placeholder validation
  - Age filter (0-30 days) - only retrieve older memories
  - Limit control (1-10 memories per request)
  - Manual memory management (view, edit, delete)
  - Smart context injection with configurable title & instructions
- **RAG (Retrieval Augmented Generation)** - knowledge documents
  - Upload text/markdown documents for AI context
  - Automatic chunking with configurable size (128-2048 chars)
  - Chunk overlap control (0-256 chars) for context preservation
  - Semantic search across chunks (cosine similarity + keyword boost)
  - Document processing with progress tracking
  - Limit control (1-10 chunks per request)
  - Configurable title & instructions for knowledge context
- **Embedding Models** - local semantic understanding
  - all-MiniLM-L6-v2 (~25 MB) - fast, basic quality
  - mxbai-embed-large (~335 MB) - slower, high quality
  - Download queue with progress tracking
  - Automatic model selection for Memory & RAG

#### ğŸ¨ Appearance & Accessibility
- **Three themes** - Light, Dark, System
- **Two color styles** - Dynamic (from wallpaper), Neutral (grayscale)
- **Three fonts** - Roboto, System, Monospace
- **Four text sizes** - Small, Medium, Large, Extra Large
- **Real-time theme switching** - no restart required

### ğŸš§ Coming Soon

#### ğŸŒ Additional Models & Providers
- More OpenRouter models (expand from current selection)
- Groq (ultra-fast inference)
- Additional multimodal models as they become available

#### ğŸ”’ Security Enhancements
- Biometric authentication option
- Screenshot prevention for sensitive screens
- Root detection warnings
- Additional ProGuard hardening

#### ğŸŒ OpenRouter (NEW!)
**Claude:**
- **Claude Sonnet 4.5 / 4 / 3.7** - balanced performance
- **Claude Opus 4.5** - most capable
- **Claude Haiku 4.5 / 3.5** - fast and efficient

**Llama 4:**
- **Llama 4 Maverick** - flagship with advanced reasoning
- **Llama 4 Scout** - efficient variant for fast inference

**Gemini:**
- **Gemini 3 Pro / Flash Preview** - advanced reasoning
- **Gemini 2.5 Pro / Flash** - multimodal, 1M+ context

**OpenAI:**
- **GPT-4o (2024-05-13)** - stable snapshot with vision

**Total: 14 models available** | Access to 200+ models through one API

#### ğŸ”œ Coming Soon
- More OpenRouter models (200+ available)
- Multimodal support (images, audio, video for compatible models)
- Groq (ultra-fast inference)

## ğŸ›  Technology Stack

- **Language:** Kotlin 100%
- **UI:** Jetpack Compose + Material 3 Dynamic Color
- **Architecture:** Clean Architecture (MVVM + Repository Pattern)
- **Local Storage:** Room Database + EncryptedSharedPreferences (Android Keystore)
- **Async:** Coroutines + Flow (reactive UI updates)
- **DI:** Hilt (Dagger)
- **Local AI:** Llamatik (llama.cpp Android wrapper via JNI)
- **Embeddings:** Llamatik embedding API (all-MiniLM, mxbai-embed)
- **Semantic Search:** Cosine similarity + keyword boost + exact match boost
- **API Clients:** OkHttp + Retrofit + Gson
- **Streaming:** Server-Sent Events (SSE) for real-time responses
- **Voice:** WebSocket (xAI Grok Voice Agent API) + AudioRecord + AudioTrack
- **Speech-to-Text:** Android SpeechRecognizer API
- **Multimodal:**
  - Image processing: Coil + ExifInterface
  - Compression: Custom ImageCompressor utility
  - File handling: FileProcessor utility
  - Base64 encoding for API transmission
- **Security:** Certificate Pinning, Network Security Config, API key encryption
- **Build:** Gradle 8.11+ with R8/ProGuard obfuscation

### For Developers

#### Prerequisites
- Android Studio Ladybug or newer
- Android SDK 26+ (minSdk 26, targetSdk 35)
- Gradle 8.11+
- JDK 17

#### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/YourOwnAI.git
cd YourOwnAI
```

2. **Open in Android Studio**
```bash
# Open Android Studio and select "Open an existing project"
# Navigate to the cloned directory
```

3. **Build and run**
```bash
./gradlew assembleDebug
# Or use Android Studio's Run button
```

### Building Release APK

For testing release builds (with ProGuard/R8):

1. **Using debug keystore (for testing)**
```bash
./gradlew assembleRelease
# APK location: app/build/outputs/apk/release/app-release.apk
```

2. **For production**
```bash
# Generate production keystore (one time only)
keytool -genkey -v -keystore yourownnai-release.keystore \
  -alias yourownnai -keyalg RSA -keysize 2048 -validity 10000

# Update build.gradle.kts signingConfigs with your keystore
# Then build:
./gradlew assembleRelease
```

3. **Common build issues**
- If Gradle wrapper is missing, use Android Studio's Build menu
- Clean project before release builds: `./gradlew clean`
- Check ProGuard mapping files: `app/build/outputs/mapping/release/`

### First Launch Setup

1. **Complete onboarding**
   - Choose theme (Light/Dark/System)
   - Select color style (Dynamic/Neutral)
   - Pick font (Roboto/System)
   - Adjust text size

2. **Add your API key**
   - Open Settings â†’ API Keys
   - Select provider (Deepseek, OpenAI, x.ai)
   - Enter your API key (stored encrypted with Android Keystore)
   - Test the connection

3. **Optional: Download local model**
   - Settings â†’ Local AI Models
   - Choose Qwen 2.5 1.7B (950MB) or Llama 3.2 3B (1.9GB)
   - Models download one at a time with progress tracking
   - Models are validated automatically (GGUF header check)

4. **For Voice Chat & Speech-to-Text** (optional)
   - Grant microphone permission when prompted
   - Required for speech-to-text input and voice conversations

5. **Start chatting!**
   - Select a model from the dropdown
   - Customize settings (temperature, system prompt, etc.)
   - View detailed request logs for debugging

## ğŸ“± Usage

### Basic Chat
- Type your message in any conversation
- AI responds using your selected model (API or local)
- **Reply to messages** - tap Reply button on any message
  - Visual preview appears above input field
  - Click preview to scroll to original message
  - Close button to cancel reply
  - AI receives swipe context with configurable prompt
- **API models** get enhanced context:
  - Swipe message context (if replying to a message)
  - Deep Empathy focus detection for emotional responses
  - Relevant memories retrieved via semantic search
  - RAG chunks from your knowledge documents
- **Local models** use simple system prompt + latest message
- Streaming responses with smooth animations
- All conversations stored locally and encrypted
- Rich markdown rendering:
  - **bold**, *italic*, [links](url)
  - > blockquotes
  - # Headings (H1, H2, H3)
  - Horizontal rules (---, ***, ___)

### Switching Models
- Tap model selector at top-left of chat (next to back button)
- Choose from:
  - **API models** - Deepseek, OpenAI GPT-5/4o, x.ai Grok, OpenRouter (Claude, Llama 4, Gemini)
  - **Local models** - Qwen 2.5 1.7B, Llama 3.2 3B (if downloaded)
- **Pin favorites** - tap star icon to pin frequently used models to top
- Model persists per conversation
- Multimodal capabilities shown automatically (image/document icons)

### Voice Chat
1. **Open Voice Chat** - tap microphone button on home screen
2. **First time setup**:
   - Grant microphone permission
   - Ensure x.ai API key is set (Settings â†’ API Keys)
3. **Choose voice** - tap center chip to select from 5 voices:
   - **Ara** - Female, warm and friendly
   - **Rex** - Male, confident and clear
   - **Sal** - Neutral, smooth and balanced
   - **Eve** - Female, energetic and upbeat
   - **Leo** - Male, authoritative and strong
4. **Choose personality** - tap person icon (ğŸ‘¤) to select system prompt
5. **Talk naturally**:
   - Tap microphone button to start recording
   - Speak your message
   - Tap again to stop and send
   - AI responds with voice and text
6. **Persistent history** - your voice conversations are saved and restored when you return
7. **Clear history** - tap trash icon (ğŸ—‘ï¸) in header to start fresh (keeps last 100 messages)
8. **View request logs** - tap code icon (`</>`) on AI messages to see:
   - System prompt used
   - Voice selected
   - User context included
   - Session details

### Attaching Images and Documents (NEW!)
1. **Check model support** - attachment icon appears only for multimodal models
2. **Attach files**:
   - **Tap paperclip icon** in message input (left side)
   - **Choose type** from dropdown:
     - ğŸ–¼ï¸ **Image** - Select photos from gallery
     - ğŸ“„ **Document** - Select PDF, TXT, DOC, DOCX files
3. **Preview attachments**:
   - Images show thumbnail with size and remove button
   - Documents show file name, type icon, size, and remove button
4. **Send message** - attachments are included with your text
5. **View in chat history** - attachments display in message bubbles:
   - Images show full preview (tap to view)
   - Documents show file info with type-specific icon
6. **Model limits** - automatically enforced:
   - OpenAI: 500 images or 50 documents
   - Grok: Unlimited images, 50 documents
   - Claude: 100 images, 10 PDFs
   - Llama 4: 10 images
   - Gemini: 10 files (100MB each)
7. **Supported formats vary by model**:
   - All: JPEG, PNG, GIF, WebP
   - Most: PDF, TXT
   - Some: DOC, DOCX, MD, CSV, JSON, code files

### Using Speech-to-Text (NEW!)
1. **Empty message field** - microphone icon appears (right side)
2. **Tap microphone** - starts listening
3. **Speak your message** - real-time transcription
4. **Visual feedback** - pulsating red icon while listening
5. **Tap again** - stops listening, text appears in field
6. **Edit if needed** - modify transcribed text
7. **Send** - microphone transforms into send button

### Import/Export Chat
1. **Export chat**:
   - Tap three-dot menu in chat
   - Select "Save chat" or "Save liked messages"
   - Share as text or copy to clipboard
2. **Import chat**:
   - Open drawer (â˜° menu)
   - Tap Upload button (top right corner)
   - Paste exported chat text or load .txt file
   - Tap Import
3. **Format** - exports include:
   - Chat title, model, provider
   - All messages with roles (User, Assistant, System)
   - Liked messages indicator (â¤ï¸)
   - Timestamps

### Customizing AI Behavior
1. **Settings â†’ AI Configuration**
2. Edit system prompts:
   - **System Prompt** - for API models
   - **Local System Prompt** - for offline models
3. Adjust parameters:
   - **Temperature** (0.0-2.0) - creativity vs consistency
   - **Top-P** (0.0-1.0) - diversity of word choices
   - **Max Tokens** (256-8192) - response length limit
   - **Message History** (1-25) - context window size
4. **Enable Advanced Features** (API models only):
   - **Deep Empathy** - emotional intelligence with focus detection
     - Customize focus prompt and analysis prompt
   - **Memory** - long-term memory system
     - Edit extraction prompt
     - Set memory limit (1-10)
     - Configure age filter (0-30 days)
     - Customize memory title and instructions
   - **RAG** - knowledge documents
     - Upload text/markdown documents
     - Configure chunk size (128-2048) and overlap (0-256)
     - Set chunk limit (1-10)
     - Customize RAG title and instructions
5. **Advanced Settings** - expand each section to customize:
   - Context Instructions - how AI uses additional context
   - Swipe Message Prompt - prompt for replied messages (requires `{swipe_message}` placeholder)
   - Memory Instructions - how AI interprets memories
   - RAG Instructions - how AI uses knowledge documents
   - Deep Empathy Analysis - focus detection prompt

### Managing Memories
1. **Automatic extraction** - AI extracts key facts from your messages
2. **View memories** - Settings â†’ Memory â†’ "Saved Memories"
3. **Edit memories** - tap any memory to edit or delete
4. **Configure extraction**:
   - Edit Memory Extraction Prompt (requires `{text}` placeholder)
   - Set Memory Limit (1-10 memories per request)
   - Set Age Filter (0-30 days) - only retrieve older memories
5. **Customize presentation**:
   - Memory Title - how memories are labeled in context
   - Memory Instructions - how AI should interpret memories

### Managing Knowledge Documents (RAG)
1. **Upload documents** - Settings â†’ RAG â†’ "+" button
2. **Add text/markdown** - paste or type content
3. **Automatic processing**:
   - Documents are chunked (configurable size: 128-2048 chars)
   - Chunks overlap for context preservation (0-256 chars)
   - Embeddings generated for semantic search
   - Progress bar shows processing status
4. **Delete documents** - swipe left or tap delete icon
5. **Configure retrieval**:
   - RAG Chunk Limit (1-10 chunks per request)
   - Chunk Size and Overlap in Advanced RAG Settings
6. **Customize presentation**:
   - RAG Title - how knowledge is labeled in context
   - RAG Instructions - how AI should use documents

### Debugging API Calls
1. Long press any AI message
2. Select "View Request Logs"
3. See complete context snapshot:
   - **System prompt** - active prompt for this model
   - **Enhanced context** - Swipe message, Memory, RAG chunks, Deep Empathy focus
   - **Messages** - conversation history sent to AI
   - **Model parameters** - temperature, top-p, max tokens
   - **AI flags** - Deep Empathy, Memory, RAG status
4. Copy logs for troubleshooting or sharing
5. Verify what context was actually sent to the AI

## ğŸ— Project Structure

```
YourOwnAI/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/main/
â”‚   â”‚   â”œâ”€â”€ java/com/yourown/ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dao/              # DAOs for conversations, messages, memories, documents
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ entity/           # Room entities with @Entity annotations
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ preferences/      # SettingsManager (DataStore)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ YourOwnAIDatabase.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ remote/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deepseek/         # Deepseek API client
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openai/           # OpenAI API client (GPT-5, o1/o3)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xai/              # x.ai Grok API + Voice Agent (WebSocket)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ repository/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AIConfigRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ApiKeyRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MemoryRepository.kt           # Memory with semantic search
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ KnowledgeDocumentRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentEmbeddingRepository.kt # RAG chunks + embeddings
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LocalModelRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SystemPromptRepository.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AIServiceImpl.kt              # API model service
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LlamaServiceImpl.kt           # Local model service
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EmbeddingServiceImpl.kt       # Embedding service
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ llama/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ LlamaCppWrapper.kt            # JNI wrapper for llama.cpp
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ EmbeddingWrapper.kt           # JNI wrapper for embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ dao/              # DAOs for conversations, messages, memories, documents
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ entity/           # Room entities with @Entity annotations
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ preferences/      # SettingsManager (DataStore, pinned models)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ YourOwnAIDatabase.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ remote/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deepseek/         # Deepseek API client
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openai/           # OpenAI API client (GPT-5, multimodal)
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openrouter/       # OpenRouter API client (Claude, Llama, Gemini)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ xai/              # x.ai Grok API + Voice Agent + multimodal
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ repository/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AIConfigRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ApiKeyRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MessageRepository.kt    # Auto-updates conversation timestamp
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MemoryRepository.kt     # Memory with semantic search
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ KnowledgeDocumentRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentEmbeddingRepository.kt # RAG chunks + embeddings
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LocalModelRepository.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SystemPromptRepository.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AIServiceImpl.kt              # Unified API service + multimodal routing
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LlamaServiceImpl.kt           # Local model service
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EmbeddingServiceImpl.kt       # Embedding service
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ llama/
â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ LlamaCppWrapper.kt            # JNI wrapper for llama.cpp
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ EmbeddingWrapper.kt           # JNI wrapper for embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ model/                # Models: AIConfig, Message, Memory, etc.
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ModelCapabilities.kt          # Multimodal capabilities mapping
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FileAttachment.kt             # File attachment metadata
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prompt/               # AIPrompts.kt (Deep Empathy, Memory)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ service/              # Service interfaces
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SpeechRecognitionManager.kt   # Android STT integration
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ util/                 # SemanticSearchUtil, ImageCompressor, FileProcessor
â”‚   â”‚   â”‚   â”œâ”€â”€ presentation/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ onboarding/           # First launch setup
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatScreen.kt                 # Main chat with multimodal pickers
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatViewModel.kt              # State + attachments management
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessageHandler.kt         # Message sending + AI generation
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatContextBuilder.kt         # Context assembly
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ MessageBubble.kt          # Displays text + attachments
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ MessageInput.kt           # Grok-style with mic/send/attach
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ ModelSelector.kt          # Compact, pinning support
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ AttachedImagesPreview.kt  # Image thumbnail preview
â”‚   â”‚   â”‚   â”‚   â”‚       â”œâ”€â”€ AttachedFilesPreview.kt   # File preview with icons
â”‚   â”‚   â”‚   â”‚   â”‚       â””â”€â”€ dialogs/                  # Various dialogs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceChatScreen.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VoiceChatViewModel.kt         # Real-time voice with xAI Grok
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ VoiceComponents.kt            # Waveform, voice selector, etc.
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ settings/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsScreen.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsViewModel.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsDialogs.kt
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ components/       # Advanced settings dialogs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ home/                 # Conversations list (sorted by time)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ theme/                # Material 3 theming
â”‚   â”‚   â”‚   â”œâ”€â”€ di/                       # Hilt modules
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ AppModule.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DatabaseModule.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ NetworkModule.kt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RepositoryModule.kt
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ServiceModule.kt
â”‚   â”‚   â”‚   â””â”€â”€ YourOwnAIApplication.kt
â”‚   â”‚   â”œâ”€â”€ res/
â”‚   â”‚   â”‚   â”œâ”€â”€ xml/network_security_config.xml
â”‚   â”‚   â”‚   â””â”€â”€ values/strings.xml
â”‚   â”‚   â””â”€â”€ AndroidManifest.xml
â”‚   â”œâ”€â”€ build.gradle.kts
â”‚   â””â”€â”€ proguard-rules.pro
â”œâ”€â”€ gradle/
â”œâ”€â”€ build.gradle.kts
â”œâ”€â”€ ARCHITECTURE.md           # Detailed architecture documentation
â”œâ”€â”€ SECURITY.md              # Security best practices
â”œâ”€â”€ CHANGELOG.md             # Version history
â””â”€â”€ README.md
```

## ğŸ”’ Privacy & Security

### What We Store Locally
- Chat conversations (Room Database) with attachment metadata
- Messages with full request logs (system prompt, context, parameters)
- Message attachments (images and documents stored in cache)
- Message replies (swipe message ID and text for context)
- Long-term memories extracted from conversations
- Knowledge documents with embeddings and chunks
- API keys (encrypted with Android Keystore)
- User preferences (theme, colors, fonts, text size)
- System prompts (default, local, custom)
- Pinned models preference (DataStore)
- AI configuration (temperature, top-p, max tokens, message history)
- Advanced AI settings (Deep Empathy, Memory, RAG, Swipe prompts and instructions)
- Downloaded local models (Qwen 2.5, Llama 3.2)
- Downloaded embedding models (all-MiniLM, mxbai-embed)
- **Voice Chat history** - last 100 messages saved in SharedPreferences (separate from regular chats)

### What We DON'T Collect
- âŒ No analytics or telemetry
- âŒ No crash reporting to third parties
- âŒ No user tracking or profiling
- âŒ No cloud backups
- âŒ No data mining
- âŒ No ads or monetization

### Security Measures
- **Android Keystore System** for API key encryption
- **EncryptedSharedPreferences** for sensitive settings
- **HTTPS only** with Network Security Config
- **Certificate pinning** configuration ready
- **ProGuard/R8** obfuscation for release builds
- **No root required** - works on any device
- **Memory isolation** - local models use separate memory heap

## ğŸŒ Supported AI Providers

| Provider | Models | Multimodal | Notes |
|----------|--------|------------|-------|
| Deepseek | Deepseek Chat, Deepseek Reasoner | âŒ Text only | Fast, cost-effective reasoning |
| OpenAI | GPT-5.2, GPT-5.1, GPT-4o | âœ… Images + PDF | Best quality, up to 500 images/50 files |
| x.ai (Grok) | Grok 4.1, Grok 4, Grok 3, Grok Code + **Voice API** | âœ… Images + Files | Unlimited images, 50 docs (PDF, TXT, code) |
| **OpenRouter** | **26 models total:** | | Access to 200+ models with one API key |
| â†³ Claude | Sonnet 4.5/4/3.7, Opus 4.5, Haiku 4.5/3.5 (6) | âœ… Images + PDF | 100 images, native PDF (100 pages), 32MB limit |
| â†³ Llama 4 | Maverick, Scout (2) | âœ… Images | 10 images, native multimodal, 10M context (Scout) |
| â†³ Gemini | 3 Pro/Flash, 2.5 Pro/Flash (4) | âœ… Images + PDF | 10 files, 100MB each, audio/video support |
| â†³ GPT-4o | openai/gpt-4o-2024-05-13 (1) | âœ… Images + PDF | Same as OpenAI direct |
| Local | Qwen 2.5 1.7B, Llama 3.2 3B | âŒ Text only | Completely offline via llama.cpp |

**Multimodal Stats:**
- ğŸ¨ **26 models** support images and/or documents
- ğŸ“„ **23 models** support both images AND documents
- ğŸ–¼ï¸ **3 models** support images only (Llama 4, DeepSeek V3.2 Exp)

### Multimodal Capabilities by Provider

**OpenAI (3 models):**
- Up to 500 images or 50 documents
- Formats: JPEG, PNG, GIF, WebP / PDF, TXT, DOC, DOCX
- 50MB total payload

**x.ai Grok (10 models):**
- Unlimited images (20MB each)
- Up to 50 documents (48MB each)
- Formats: JPG, PNG / PDF, TXT, MD, CSV, JSON, code files

**Claude via OpenRouter (6 models):**
- Up to 100 images (8000x8000px)
- Native PDF support (100 pages, 32MB)
- Formats: JPEG, PNG, GIF, WebP / PDF

**Llama 4 via OpenRouter (2 models):**
- Up to 10 images
- Native multimodal with early fusion
- Pre-trained on 48 images

**Gemini via OpenRouter (4 models):**
- Up to 10 files (consumer), 3,000 files (enterprise)
- 100MB per file via File API
- PDF support (30MB/2000 pages)
- Formats: JPEG, PNG, GIF, WebP / PDF, TXT, DOC, DOCX, MD, CSV

## ğŸ—º Roadmap

### Phase 1: Core Chat âœ… (Completed)
- [x] Project setup with Jetpack Compose + Hilt
- [x] Chat interface with streaming responses
- [x] Multiple conversations management
- [x] API key management (encrypted storage)
- [x] Room Database for local storage
- [x] Deepseek API integration
- [x] OpenAI API integration (GPT-5, GPT-4o, o1/o3)
- [x] x.ai (Grok) API integration
- [x] Local model integration (Llamatik/llama.cpp)
- [x] Model download manager with queue
- [x] Onboarding flow with theme customization
- [x] Settings screen with appearance dialog
- [x] Markdown rendering (bold, italic, links, blockquotes)
- [x] Request logs for debugging

### Phase 2: Advanced Features âœ… (Completed)
- [x] Embedding models download (all-MiniLM, mxbai-embed)
- [x] Long-term memory system with semantic search
- [x] Memory extraction with configurable prompts
- [x] Memory age filter (0-30 days)
- [x] RAG - Document upload (text/markdown)
- [x] Document chunking with configurable size and overlap
- [x] Semantic search with keyword boost
- [x] Deep Empathy mode with focus detection
- [x] Message reply (swipe) - Telegram-style with visual preview
- [x] Advanced settings UI with collapsible sections
- [x] Customizable prompts and instructions for all features
- [x] Request logs with full context (Memory, RAG, Deep Empathy, Swipe)
- [x] Markdown rendering (headings, horizontal rules)
- [x] Placeholder validation for prompts

### Phase 3: Multimodal & Voice âœ… (Completed)
- [x] Voice chat - real-time voice conversation with xAI Grok
- [x] Voice chat persistent history (last 100 messages)
- [x] Speech-to-text input (Android STT)
- [x] OpenRouter integration - 13 models (Claude, Llama 4, Gemini, GPT-4o)
- [x] Context Inheritance - fork conversations with inherited message history
- [x] Improved Memory filtering - excludes non-meaningful responses
- [x] **Multimodal support - images and documents**
  - [x] Image attachment support (compress, preview, display)
  - [x] Document attachment support (PDF, TXT, DOC, DOCX)
  - [x] Model capabilities mapping (26 models)
  - [x] OpenAI multimodal API integration
  - [x] x.ai Grok multimodal API integration
  - [x] Claude multimodal via OpenRouter
  - [x] Attachment UI components (preview, display in chat)
- [x] **Keyboard sound & vibration** ğŸ¹
  - [x] Realistic typing sounds when AI responds
  - [x] Haptic feedback (vibration) synchronized with typing
  - [x] Settings toggle for sound and vibration
  - [x] Smart detection of sentence endings
  - [x] File picker and image picker integration
  - [x] Base64 encoding and compression
- [x] **UI improvements**
  - [x] Pin favorite models to top of list
  - [x] Grok-style message input (mic/send dynamic switching)
  - [x] Attachment dropdown menu (Image vs Document)
  - [x] Chat sorting by last message time
  - [x] ModelSelector moved to top row (compact)
  - [x] Chat title moved to bottom row (centered)
- [ ] Usage tracking (tokens, cost)
- [ ] More OpenRouter models (expand selection)

### Phase 4: Polish & Security
- [ ] Biometric authentication
- [ ] Screenshot prevention for sensitive screens
- [ ] Root detection
- [ ] Additional ProGuard hardening
- [ ] Performance optimization for large conversations
- [ ] Accessibility improvements

### Phase 5: Distribution
- [ ] Production keystore setup
- [ ] Google Play release
- [ ] F-Droid release
- [ ] Documentation and tutorials

### Future Considerations
- [ ] Optional Supabase sync
- [ ] Import from Character.AI, Replika, etc.
- [ ] Image generation
- [ ] Custom voice cloning
- [ ] Plugin system

## ğŸ¤ Contributing

This project is open source and contributions are welcome! Whether you're fixing bugs, adding features, or improving documentation - we appreciate your help.

### How to Contribute
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow Kotlin coding conventions
- Write clean, documented code
- Test on both debug and release builds
- Keep UI simple and intuitive
- Respect user privacy - no telemetry without explicit opt-in

## ğŸ› Known Issues & Solutions

### Local Model Crashes
**Problem:** App crashes when using local models (Qwen/Llama)
**Solution:** 
- Llamatik is not thread-safe - we use Mutex to prevent concurrent access
- Models are validated on startup (GGUF header check)
- Corrupt files are automatically deleted
- Download queue prevents OOM by loading one model at a time

### OutOfMemoryError During Downloads
**Problem:** App crashes with OOM when downloading large models
**Solution:**
- `largeHeap="true"` in AndroidManifest (512MB heap)
- Separate `@DownloadClient` OkHttpClient without body logging
- 4KB buffer size to reduce memory pressure
- Automatic garbage collection every 10%

### OpenAI API Parameter Errors
**Problem:** "Unsupported parameter: 'max_tokens'" or "Unsupported value: 'temperature'"
**Solution:**
- GPT-5/GPT-4.1 use `max_completion_tokens` instead of `max_tokens`
- Reasoning models (o1/o3) don't support `temperature`/`top_p`
- Detection logic automatically handles these differences

### ProGuard Build Issues
**Problem:** Release build crashes due to obfuscation
**Solution:**
- Comprehensive keep rules for Hilt, Llamatik, Gson, Room
- Native method preservation for JNI
- Error logs preserved, debug logs removed

## â“ FAQ

**Q: How much does this cost?**
A: The app is free and open source. You only pay for API usage directly to providers (e.g., OpenAI, Deepseek). Local models are completely free after download.

**Q: Is my data safe?**
A: Yes. Everything is stored locally on your device. API keys are encrypted with Android Keystore. No data is sent to our servers (we don't have any).

**Q: Can I use this offline?**
A: Yes! Download Qwen 2.5 (950MB) or Llama 3.2 (1.9GB) and chat completely offline. No internet required.

**Q: Which API provider is best?**
A: 
- **Deepseek** - Best price/performance ratio
- **OpenAI GPT-4o** - Highest quality
- **x.ai Grok** - Fast reasoning
- **Local models** - Privacy (offline), free after download

**Q: Why are local models crashing?**
A: Ensure you're on the latest version. We've added:
- Thread-safe model loading (Mutex)
- Automatic corruption detection
- Download queue system
- Memory optimization (largeHeap)

**Q: What is Deep Empathy mode?**
A: Deep Empathy analyzes your messages for strong emotional moments and helps the AI respond with appropriate emotional intelligence. It automatically detects focus points (actions, feelings, desires) and injects them into the AI's context. Only works with API models.

**Q: How does Memory work?**
A: The AI automatically extracts key facts from your conversations and stores them. The system filters out non-meaningful responses (e.g., "ĞĞµÑ‚ ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸") to keep only actionable memories. When you chat, it retrieves relevant memories (using semantic search) and includes them in context. You can view, edit, or delete memories anytime. Memory has an age filter - by default, only memories older than 2 days are retrieved.

**Q: What is RAG?**
A: Retrieval Augmented Generation. Upload text documents (personal notes, articles, guides) and the AI will use them to provide more informed responses. Documents are chunked, embedded, and retrieved using semantic search.

**Q: Do Memory and RAG work offline?**
A: No. These features require embedding models for semantic search and only work with API models (not local models). Embedding models are downloaded separately (all-MiniLM ~25MB or mxbai-embed ~335MB).

**Q: Can I customize the prompts?**
A: Yes! Almost every prompt is customizable:
- System prompt for API models
- Local system prompt for offline models
- Memory extraction prompt (how AI extracts memories)
- Swipe message prompt (how AI uses replied messages)
- Deep Empathy focus prompt and analysis prompt
- Context instructions, Memory instructions, RAG instructions
All prompts have placeholder validation to prevent breaking functionality.

**Q: How does message reply (swipe) work?**
A: Tap the Reply button on any message to add it to context. A preview appears above the input field showing what you're replying to. The AI receives this context with a configurable prompt like "ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ ÑĞ²Ğ°Ğ¹Ğ¿Ğ½ÑƒĞ» ÑÑ‚Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ â€” ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ²ĞµÑ€Ğ½ÑƒĞ»ÑÑ Ğº ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñƒ: {message}". This helps the AI understand you're referring back to a specific moment in conversation.

**Q: How does Voice Chat work?**
A: Voice Chat uses xAI Grok Voice Agent API for real-time speech-to-text and text-to-speech. You speak â†’ Grok transcribes â†’ AI responds â†’ Grok reads response aloud. Choose from 5 voices (Ara, Rex, Sal, Eve, Leo) and use your custom system prompts. Messages are session-only (not saved).

**Q: Are Voice Chat messages saved?**
A: Yes! Voice Chat now saves your conversation history locally (last 100 messages max). When you reopen Voice Chat, you'll see your previous messages. This is separate from regular chats - voice messages are stored in SharedPreferences, not the main database. You can clear history anytime using the trash icon.

**Q: Can I use Voice Chat offline?**
A: No. Voice Chat requires internet connection and xAI API key. It uses Grok's real-time voice API (WebSocket) for speech recognition and synthesis.

**Q: Can I change voice or personality during conversation?**
A: Yes! You can switch voices (Ara, Rex, Sal, Eve, Leo) or system prompts anytime. The session will automatically reconnect with new settings while keeping your message history in the current session.

**Q: Does the app have automatic backup?**
A: Yes! Android Auto Backup is enabled. Your chats, settings, and data are automatically backed up to Google Drive (if enabled) or during device transfer. API keys are intentionally excluded for security. Backup happens automatically every 24 hours when connected to WiFi and charging.

**Q: Can I export and import chats?**
A: Yes! Use the three-dot menu in chat to export as text. To import, open the drawer and tap the Upload button (top right). You can paste text or load .txt files. Format is preserved including model, provider, roles, and liked messages.

**Q: What is Context Inheritance and how do I use it?**
A: Context Inheritance lets you "fork" a conversation - create a new chat that inherits message history from an existing chat. When you tap "+ New Chat", a dialog appears where you can select a source chat (or choose "None" for a fresh start). If you select a source, the last N message pairs (based on your Message History Limit setting, default 10) are automatically loaded into context. As you continue the new conversation, inherited messages are gradually replaced by new ones. This is useful for continuing a topic in a new context, switching AI models while keeping history, or branching off from a specific point in a conversation.

**Q: Can I contribute?**
A: Absolutely! Fork the repo, make changes, and submit a PR. All contributions welcome.

**Q: How do I attach images or documents?**
A: 
1. Select a multimodal model (GPT-5, Grok, Claude, etc.)
2. Tap the paperclip icon in message input
3. Choose "Image" or "Document" from dropdown
4. Select file from your device
5. Preview appears - tap X to remove if needed
6. Type your message and send
Images are automatically compressed. Model limits are enforced (e.g., Grok allows unlimited images, Claude allows 100).

**Q: Which models support images and documents?**
A: **26 models** support multimodal:
- **OpenAI** (3): GPT-5.2, 5.1, 4o - images + PDF/TXT/DOC
- **x.ai Grok** (10): All models - unlimited images + PDF/TXT/code files
- **Claude** (6): All 4.5/4/3.7/3.5 via OpenRouter - 100 images + native PDF
- **Llama 4** (2): Maverick, Scout - 10 images each
- **Gemini** (4): 3 Pro/Flash, 2.5 Pro/Flash - 10 files, audio/video support
- **GPT-4o** (1): Via OpenRouter - same as OpenAI direct

**Q: Are there limits on attachments?**
A: Yes, each model has specific limits:
- **GPT-5/4o**: 500 images or 50 docs, 50MB total
- **Grok**: Unlimited images (20MB each), 50 docs (48MB each)
- **Claude**: 100 images, 10 PDFs, 32MB request size
- **Llama 4**: 10 images only
- **Gemini**: 10 files (100MB each), PDF up to 30MB/2000 pages
Limits are automatically enforced in the UI.

**Q: Can I use speech-to-text to write messages?**
A: Yes! When the message field is empty, tap the microphone icon. Speak your message, tap again to stop. The transcribed text appears in the field for you to edit before sending. This uses Android's built-in Speech Recognition (works offline if you have language packs installed).

**Q: How do I pin my favorite models?**
A: Tap the star icon next to any model in the model selector dropdown. Pinned models appear at the top of the list for quick access. Your pins are saved across app restarts.

**Q: Will this be on Google Play?**
A: Yes, once we reach stable 1.0. For now, download APK from GitHub Releases.

## ğŸ“„ License

This project is licensed under the **Apache License 2.0** - see the [LICENSE](LICENSE) file for details.

### Why Apache 2.0?
- âœ… Free for personal and commercial use
- âœ… Modification and distribution allowed
- âœ… Patent protection
- âœ… Compatible with Google Play and F-Droid

## âš ï¸ Disclaimer

This application allows unrestricted AI interactions. Users are responsible for:
- Their own API usage and costs
- Compliance with AI provider terms of service
- Legal and ethical use of the software
- Content generated by AI models

The developers assume no liability for how this software is used.

---

## ğŸ“š Documentation

- [ARCHITECTURE.md](ARCHITECTURE.md) - Detailed architecture and design patterns
- [CONTRIBUTING.md](CONTRIBUTING.md) - How to contribute to the project
- [SECURITY.md](SECURITY.md) - Security best practices and compliance
- [CHANGELOG.md](CHANGELOG.md) - Version history and changes
- [CHAT_IMPLEMENTATION_PLAN.md](CHAT_IMPLEMENTATION_PLAN.md) - Chat feature specifications
- [LLAMA_CPP_INTEGRATION.md](LLAMA_CPP_INTEGRATION.md) - Local model integration details

---

**Made with â¤ï¸ for privacy-conscious humans who believe in digital freedom**

*"Your data. Your AI. Your rules."*

